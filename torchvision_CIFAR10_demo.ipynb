{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61786d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Compose, ToTensor, Grayscale, Normalize, Resize\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "\n",
    "from transights.utils import FolderScanner as fs\n",
    "from transights.utils import Pickler\n",
    "from transights.transforms import (FileToPIL,\n",
    "                             PILToNumpy,\n",
    "                             FlattenArray,\n",
    "                             DebugTransform,\n",
    "                             ProjectTransform,\n",
    "                             PyTorchOutput,\n",
    "                             PyTorchEmbedding,\n",
    "                             ToDevice,\n",
    "                             FlattenTensor,\n",
    "                             CachingTransform)\n",
    "\n",
    "from transights.aggregator import DataSetAggregator, DataLoaderAggregator\n",
    "\n",
    "random_state = 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a6abb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path.cwd() / \"data\" / \"CIFAR10\"\n",
    "\n",
    "DATA_PATH_TRAIN = Path(DATA_PATH, \"train\")\n",
    "DATA_PATH_TEST = Path(DATA_PATH, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9c5eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device:\", DEVICE.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a967f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_pretrained = torch.load(\"weights_resnet18_cifar10.pth\", map_location=DEVICE)\n",
    "\n",
    "# load model with pre-trained weights\n",
    "model = resnet18(num_classes=10)\n",
    "model.load_state_dict(weights_pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2463df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "# this prevents the following error when trying to download the dataset:\n",
    "# SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea3fbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the transformation pipeline\n",
    "transform_pipeline = Compose([\n",
    "    ToTensor(),\n",
    "    Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n",
    "    ToDevice(DEVICE),\n",
    "    PyTorchEmbedding(model, device=DEVICE),\n",
    "    FlattenTensor(),\n",
    "    ToDevice('cpu'),\n",
    "])\n",
    "\n",
    "dataset = CIFAR10(root=DATA_PATH,\n",
    "                  train=False,\n",
    "                  transform=transform_pipeline,\n",
    "                  download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee45c631",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = DataSetAggregator(dataset, batch_size=16)\n",
    "test_embedding_result = agg.transform()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b8ec63",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a451046b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embedding_result[0].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c5d009",
   "metadata": {},
   "source": [
    "## Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6142640",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embedding_result[1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7091da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "\n",
    "# Create the UMAP reducer instance\n",
    "reducer = UMAP(n_neighbors=15, # default 15, The size of local neighborhood (in terms of number of neighboring sample points) used for manifold approximation.\n",
    "               n_components=2, # default 2, The dimension of the space to embed into.\n",
    "               metric='euclidean', # default 'euclidean', The metric to use to compute distances in high dimensional space.\n",
    "               n_epochs=1000, # default None, The number of training epochs to be used in optimizing the low dimensional embedding. Larger values result in more accurate embeddings. \n",
    "               learning_rate=1.0, # default 1.0, The initial learning rate for the embedding optimization.\n",
    "               init='spectral', # default 'spectral', How to initialize the low dimensional embedding. Options are: {'spectral', 'random', A numpy array of initial embedding positions}.\n",
    "               min_dist=0.1, # default 0.1, The effective minimum distance between embedded points.\n",
    "               spread=1.0, # default 1.0, The effective scale of embedded points. In combination with ``min_dist`` this determines how clustered/clumped the embedded points are.\n",
    "               low_memory=False, # default False, For some datasets the nearest neighbor computation can consume a lot of memory. If you find that UMAP is failing due to memory constraints consider setting this option to True.\n",
    "               set_op_mix_ratio=1.0, # default 1.0, The value of this parameter should be between 0.0 and 1.0; a value of 1.0 will use a pure fuzzy union, while 0.0 will use a pure fuzzy intersection.\n",
    "               local_connectivity=1, # default 1, The local connectivity required -- i.e. the number of nearest neighbors that should be assumed to be connected at a local level.\n",
    "               repulsion_strength=1.0, # default 1.0, Weighting applied to negative samples in low dimensional embedding optimization.\n",
    "               negative_sample_rate=5, # default 5, Increasing this value will result in greater repulsive force being applied, greater optimization cost, but slightly more accuracy.\n",
    "               transform_queue_size=4.0, # default 4.0, Larger values will result in slower performance but more accurate nearest neighbor evaluation.\n",
    "               a=None, # default None, More specific parameters controlling the embedding. If None these values are set automatically as determined by ``min_dist`` and ``spread``.\n",
    "               b=None, # default None, More specific parameters controlling the embedding. If None these values are set automatically as determined by ``min_dist`` and ``spread``.\n",
    "               random_state=random_state, # default: None, If int, random_state is the seed used by the random number generator;\n",
    "               metric_kwds=None, # default None) Arguments to pass on to the metric, such as the ``p`` value for Minkowski distance.\n",
    "               angular_rp_forest=False, # default False, Whether to use an angular random projection forest to initialise the approximate nearest neighbor search.\n",
    "               target_n_neighbors=-1, # default -1, The number of nearest neighbors to use to construct the target simplcial set. If set to -1 use the ``n_neighbors`` value.\n",
    "               #target_metric='categorical', # default 'categorical', The metric used to measure distance for a target array is using supervised dimension reduction. By default this is 'categorical' which will measure distance in terms of whether categories match or are different. \n",
    "               #target_metric_kwds=None, # dict, default None, Keyword argument to pass to the target metric when performing supervised dimension reduction. If None then no arguments are passed on.\n",
    "               #target_weight=0.5, # default 0.5, weighting factor between data topology and target topology.\n",
    "               transform_seed=42, # default 42, Random seed used for the stochastic aspects of the transform operation.\n",
    "               verbose=False, # default False, Controls verbosity of logging.\n",
    "               unique=False, # default False, Controls if the rows of your data should be uniqued before being embedded. \n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae881b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('umap', reducer),\n",
    "])\n",
    "\n",
    "# Embeddings\n",
    "X = test_embedding_result[0]\n",
    "\n",
    "# Class indices\n",
    "y = test_embedding_result[1]\n",
    "\n",
    "# Map class index to label\n",
    "labels = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "y_str = [labels[i] for i in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e96e423",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f6eccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_reduced_embedding = pipeline.transform(X)\n",
    "test_reduced_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab83df26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "def plot_2d(data, color=None, hover_name=None):\n",
    "    fig = px.scatter(x=data[:, 0],\n",
    "                     y=data[:, 1],\n",
    "                     color=color,\n",
    "                     hover_name=hover_name)\n",
    "    fig.update_traces(marker=dict(size=3,\n",
    "                                  line=dict(color='black',\n",
    "                                            width=0.1)))\n",
    "    \n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9591f315",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_2d_fig = plot_2d(data=test_reduced_embedding,\n",
    "                           color=y,\n",
    "                           hover_name=y_str)\n",
    "embedding_2d_fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
