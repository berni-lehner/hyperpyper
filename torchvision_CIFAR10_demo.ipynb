{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61786d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Compose, ToTensor, Grayscale, Normalize, Resize\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "\n",
    "from transights.utils import FolderScanner as fs\n",
    "from transights.utils import Pickler\n",
    "from transights.transforms import (FileToPIL,\n",
    "                             PILToNumpy,\n",
    "                             FlattenArray,\n",
    "                             DebugTransform,\n",
    "                             ProjectTransform,\n",
    "                             PyTorchOutput,\n",
    "                             PyTorchEmbedding,\n",
    "                             ToDevice,\n",
    "                             FlattenTensor,\n",
    "                             CachingTransform)\n",
    "\n",
    "from transights.aggregator import DataLoaderAggregator\n",
    "\n",
    "random_state = 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd9c5eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: CUDA\n"
     ]
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device:\", DEVICE.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a967f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# download pre-trained weights\n",
    "response = requests.get(\n",
    "    \"https://unlearning-challenge.s3.eu-west-1.amazonaws.com/weights_resnet18_cifar10.pth\"\n",
    ")\n",
    "open(\"weights_resnet18_cifar10.pth\", \"wb\").write(response.content)\n",
    "weights_pretrained = torch.load(\"weights_resnet18_cifar10.pth\", map_location=DEVICE)\n",
    "\n",
    "# load model with pre-trained weights\n",
    "#model = resnet18(weights=None, num_classes=10)\n",
    "model = resnet18(num_classes=10)\n",
    "model.load_state_dict(weights_pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ea3fbf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = Path(r\"E:\\Dropbox\\git\\CIFAR10\")\n",
    "DATA_PATH_TRAIN = Path(DATA_PATH, \"train\")\n",
    "DATA_PATH_TEST = Path(DATA_PATH, \"test\")\n",
    "\n",
    "# Create the transformation pipeline\n",
    "transform_pipeline = Compose([\n",
    "    ToTensor(),\n",
    "    Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ToDevice(DEVICE),\n",
    "    PyTorchEmbedding(model, device=DEVICE),\n",
    "    ToDevice('cpu'),\n",
    "    FlattenTensor(),\n",
    "])\n",
    "\n",
    "dataset = CIFAR10(root=DATA_PATH_TEST,\n",
    "                  train=False,\n",
    "                  transform=transform_pipeline,\n",
    "                  download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5b8dc8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR10\n",
       "    Number of datapoints: 10000\n",
       "    Root location: E:\\Dropbox\\git\\CIFAR10\\test\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.201))\n",
       "               ToDevice()\n",
       "               PyTorchEmbedding()\n",
       "               ToDevice()\n",
       "               FlattenTensor()\n",
       "           )"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "95c16915",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(dataset,\n",
    "                                          batch_size=2,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "40dd3b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_batches = []\n",
    "\n",
    "# Iterate over the DataLoader and aggregate all mini batches\n",
    "for batch in data_loader:\n",
    "    mini_batches.append(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cc12d7a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mini_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4f93d6bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transights.dataset import GenericDataset\n",
    "\n",
    "isinstance(data_loader.dataset, GenericDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "57400b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "full = data_loader.collate_fn(mini_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "32ba1b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader.*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6af21f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ed0e0560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_batches[1][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1c4ec5b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 8])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_batches[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "16d7291a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mini_batches[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee45c631",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = DataLoaderAggregator(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd67aefb",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m test_embedding_result \u001b[38;5;241m=\u001b[39m \u001b[43magg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\Dropbox\\github\\transights\\transights\\aggregator\\Aggregator.py:106\u001b[0m, in \u001b[0;36mDataLoaderAggregator.transform\u001b[1;34m(self, cache_file)\u001b[0m\n\u001b[0;32m    104\u001b[0m         Pickler\u001b[38;5;241m.\u001b[39msave_data(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_full_batch, cache_file)\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 106\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_full_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_full_batch\n",
      "File \u001b[1;32mE:\\Dropbox\\github\\transights\\transights\\aggregator\\Aggregator.py:121\u001b[0m, in \u001b[0;36mDataLoaderAggregator.__transform\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m         mini_batches\u001b[38;5;241m.\u001b[39mappend(batch)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# Turn the list of mini batches into a full batch\u001b[39;00m\n\u001b[1;32m--> 121\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_full_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmini_batches\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_full_batch\n",
      "File \u001b[1;32mE:\\Dropbox\\github\\transights\\transights\\aggregator\\Aggregator.py:47\u001b[0m, in \u001b[0;36mDataLoaderAggregator.collate_fn\u001b[1;34m(self, batch_list)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Separate items from the batch_list\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m batch_list:\n\u001b[1;32m---> 47\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m():\n\u001b[0;32m     48\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m full_batch:\n\u001b[0;32m     49\u001b[0m             full_batch[key] \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "test_embedding_result = agg.transform()#cache_file=test_embedding_pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56482bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embedding_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
